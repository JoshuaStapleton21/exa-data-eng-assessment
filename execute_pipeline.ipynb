{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "import tools.read_data as rd\n",
    "import pandas as pd\n",
    "import unittest\n",
    "import time\n",
    "import json\n",
    "import importlib\n",
    "for k,v in list(sys.modules.items()):\n",
    "    if k.startswith('tools'):\n",
    "        importlib.reload(v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.418402910232544\n"
     ]
    }
   ],
   "source": [
    "# read in the json data using a generator method\n",
    "patient_json_list = []\n",
    "start = time.time()\n",
    "for json_obj in rd.read_json_files('data'):\n",
    "    patient_json_list.append(json_obj)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.676032781600952\n"
     ]
    }
   ],
   "source": [
    "# read in the json data using a standard method\n",
    "patient_json_list_alt = []\n",
    "start = time.time()\n",
    "pfl = rd.get_patient_file_list('data')\n",
    "for json_obj in pfl:\n",
    "    patient_json_list_alt.append(rd.read_patient_file('data', json_obj))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have also implemented functions to read in the data from a database or an API - these are not implemented in this example\n",
    "# patient_json_list = rd.get_json_objects_from_API('https://www.example-patient-api.com/get-patient-FHIR-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the two different methods correctly calculated the same list\n",
    "assert patient_json_list == patient_json_list_alt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests for data quality / correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.346s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.262s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.150s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.485s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 11.012s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.420s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.327s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.216s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.494s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.556s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.073s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.244s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.438s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 5.154s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.269s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.106s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.150s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.365s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.182s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.365s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.296s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.516s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.112s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.324s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.133s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.240s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.055s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.406s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.205s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.174s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.509s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.125s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.304s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.387s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.212s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.286s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.191s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.129s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.244s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 2.789s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.118s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.541s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.228s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.389s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.115s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.248s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.120s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.312s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.052s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.133s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.128s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.400s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.219s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.278s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.112s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.102s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.548s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.236s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.396s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.287s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.253s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.363s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 2.214s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.120s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.223s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.471s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.174s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.359s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.600s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.961s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.363s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.072s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.415s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.187s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.080s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.240s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 1.409s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 2.876s\n",
      "\n",
      "OK\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.419s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run all tests on the incoming data\n",
    "from tools.data_tests import TestFHIRData\n",
    "\n",
    "test_runner = unittest.TextTestRunner()\n",
    "for json_obj in patient_json_list:\n",
    "    TestFHIRData.JSON_OBJ = json_obj\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestFHIRData)\n",
    "    test_results = test_runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FFFF\n",
      "======================================================================\n",
      "FAIL: test_all_fields_in_patient (tools.data_tests.TestFHIRData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshuastapleton/Desktop/EMIS_interview/exa-data-eng-assessment/tools/data_tests.py\", line 43, in test_all_fields_in_patient\n",
      "    self.assertIn(field, expected_fields, msg=f\"{field} field not found in expected fields list\")\n",
      "AssertionError: 'subject' not found in ['resourceType', 'fhir_comments', 'id', 'implicitRules', 'implicitRules__ext', 'language', 'language__ext', 'meta', 'contained', 'extension', 'modifierExtension', 'text', 'active', 'active__ext', 'address', 'birthDate', 'birthDate__ext', 'communication', 'contact', 'deceasedBoolean', 'deceasedBoolean__ext', 'deceasedDateTime', 'deceasedDateTime__ext', 'gender', 'gender__ext', 'generalPractitioner', 'identifier', 'link', 'managingOrganization', 'maritalStatus', 'multipleBirthBoolean', 'multipleBirthBoolean__ext', 'multipleBirthInteger', 'multipleBirthInteger__ext', 'name', 'photo', 'telecom'] : subject field not found in expected fields list\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_json_obj_is_fhir_bundle (tools.data_tests.TestFHIRData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshuastapleton/Desktop/EMIS_interview/exa-data-eng-assessment/tools/data_tests.py\", line 20, in test_json_obj_is_fhir_bundle\n",
      "    bundle = Bundle.parse_obj(self.JSON_OBJ)\n",
      "pydantic.error_wrappers.ValidationError: 5 validation errors for Bundle\n",
      "entry -> 0 -> resource -> __root__ -> status\n",
      "  field required (type=value_error.missing)\n",
      "entry -> 1 -> resource -> name -> 0 -> given\n",
      "  value is not a valid list (type=type_error.list)\n",
      "entry -> 1 -> resource -> socialSecurityNumber\n",
      "  extra fields not permitted (type=value_error.extra)\n",
      "entry -> 2 -> resource -> name -> 0 -> given\n",
      "  value is not a valid list (type=type_error.list)\n",
      "entry -> 3 -> resource -> __root__ -> status\n",
      "  field required (type=value_error.missing)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshuastapleton/Desktop/EMIS_interview/exa-data-eng-assessment/tools/data_tests.py\", line 22, in test_json_obj_is_fhir_bundle\n",
      "    self.fail(\"JSON object is not a FHIR Bundle\")\n",
      "AssertionError: JSON object is not a FHIR Bundle\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_only_one_patient_field_per_bundle (tools.data_tests.TestFHIRData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshuastapleton/Desktop/EMIS_interview/exa-data-eng-assessment/tools/data_tests.py\", line 34, in test_only_one_patient_field_per_bundle\n",
      "    self.assertEqual(patient_count, 1, msg=\"Multiple patient fields found in bundle\")\n",
      "AssertionError: 2 != 1 : Multiple patient fields found in bundle\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_patient_is_first_entry_in_list (tools.data_tests.TestFHIRData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshuastapleton/Desktop/EMIS_interview/exa-data-eng-assessment/tools/data_tests.py\", line 15, in test_patient_is_first_entry_in_list\n",
      "    self.assertEqual(self.JSON_OBJ['entry'][0]['resource']['resourceType'], \"Patient\", msg=\"Patient object not first in entry list\")\n",
      "AssertionError: 'Observation' != 'Patient'\n",
      "- Observation\n",
      "+ Patient\n",
      " : Patient object not first in entry list\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.024s\n",
      "\n",
      "FAILED (failures=4)\n"
     ]
    }
   ],
   "source": [
    "# example test failure\n",
    "with open(\"resources/bad_example.json\") as f:\n",
    "    bad_json_obj = json.load(f)\n",
    "\n",
    "TestFHIRData.JSON_OBJ = bad_json_obj\n",
    "test_suite = unittest.TestLoader().loadTestsFromTestCase(TestFHIRData)\n",
    "test_results = test_runner.run(test_suite)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic / local implementation of pipeline using filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhir.resources.patient import Patient\n",
    "from fhir.resources.bundle import Bundle\n",
    "\n",
    "FHIR_patient_object_list = [Patient.parse_obj(Bundle.parse_obj(patient_json).entry[0].resource) for patient_json in patient_json_list]\n",
    "patient_df = rd.patients_to_dataframe(FHIR_patient_object_list).drop(columns=['resource_type']) # we can drop this column because it is constant by definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the raw tabular data to a csv file. This needs to be normalized and cleaned before it can be used for analysis.\n",
    "patient_df.to_csv('data_output/patient_data_tabular_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploding column: address\n",
      "exploding column: communication\n",
      "exploding column: identifier\n",
      "exploding column: name\n",
      "exploding column: telecom\n"
     ]
    }
   ],
   "source": [
    "# 1NF normalization - each table cell should have a single value\n",
    "# the columns in the dataframe in need of normalization are extension, address, maritalStatus, name, telecom, etc.\n",
    "# a naive solution would be to explode the columns that are lists. This, however, tends to become monolithic, as the number of table rows grows exponentially.\n",
    "print(\"exploding column: extension\")\n",
    "patient_exploded_df = patient_df.explode('extension') # start by exploding extension - the first column of type list\n",
    "for column in patient_df.columns.drop('extension'):\n",
    "    if type(patient_df[column][0]) == list:\n",
    "        print(\"exploding column: \" + column)\n",
    "        patient_exploded_df = patient_exploded_df.explode(column)\n",
    "\n",
    "patient_exploded_df.to_csv('data_output/1NF_data/patient_data_tabular.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploding column: extension\n",
      "exploding column: address\n",
      "exploding column: communication\n",
      "exploding column: identifier\n",
      "exploding column: name\n",
      "exploding column: telecom\n"
     ]
    }
   ],
   "source": [
    "# 2NF normalization - create additional tables for initial table cells with multiple/list entires\n",
    "# this is a more complex solution, but it is more scalable, easier to maintain, and there is less data redundancy\n",
    "patient_df_2NF = patient_df.copy()\n",
    "\n",
    "for column in patient_df_2NF.columns:\n",
    "    if type(patient_df_2NF[column][0]) == list:\n",
    "        print(\"exploding column: \" + column)\n",
    "        patient_exploded_df = patient_df_2NF.explode(column)\n",
    "        patient_df_2NF = patient_df_2NF.drop(columns=[column])\n",
    "\n",
    "        # drop all columns from the exploded dataframe that are in the original dataframe except ID\n",
    "        NF_columns = list(patient_df_2NF.columns)\n",
    "        NF_columns.remove('id')\n",
    "        patient_exploded_df.drop(columns=NF_columns, inplace=True)\n",
    "        patient_exploded_df.to_csv('data_output/2NF_data/patient_data_tabular_' + column + '.csv', index=False)\n",
    "\n",
    "# finally, write the original table with all multi-value columns removed to a csv file\n",
    "patient_df_2NF.to_csv('data_output/2NF_data/patient_data_tabular.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  we can further expand the table by identifying values which are FHIR objects and splitting them up by field, however this can get tricky with string parsing\n",
    "# patient_1NF_df = pd.read_csv('data_output/1NF_data/patient_data_tabular.csv')\n",
    "# for column in patient_1NF_df.columns:\n",
    "#     # if the column starts with 'resource'\n",
    "#     first_column_value = patient_1NF_df[column].values[0]\n",
    "#     if type(first_column_value) == str and first_column_value.startswith('resource_type'):\n",
    "#         print(\"Fields of column:\", column)\n",
    "#         for field in first_column_value.split(' '):\n",
    "#             print(\"--\",field)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL implementation of pipeline with database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.create_database as cd\n",
    "import tools.update_database as ud\n",
    "\n",
    "for k,v in list(sys.modules.items()):\n",
    "    if k.startswith('tools'):\n",
    "        importlib.reload(v)\n",
    "\n",
    "# get the connection to the patient database, creating it if it does not yet exist\n",
    "patient_database = cd.create_patient_database()\n",
    "\n",
    "# # create the tables in the patient database - these correspond to the csv files in the data_output folder generated in the previous steps\n",
    "# ud.create_tables(patient_database)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
